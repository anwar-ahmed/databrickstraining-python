{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Course Overview and Setup\n## ETL Part 1: Data Extraction\n\nIn this course data engineers access data where it lives and then apply data extraction best practices, including schemas, corrupt record handling, and parallelized code. By the end of this course, you will extract data from multiple sources, use schema inference and apply user-defined schemas, and navigate Databricks and Spark documents to source solutions.\n\n** The course is composed of the following lessons:**  \n1. Course Overview and Setup\n2. ETL Process Overview\n3. Connecting to Azure Blob Storage\n4. Connecting to JDBC\n5. Applying Schemas to JSON Data\n6. Corrupt Record Handling\n7. Loading Data and Productionalizing\n8. Capstone Project"],"metadata":{}},{"cell_type":"markdown","source":["# Getting Started on Databricks\n\n## In this lesson you:\n* Log into Databricks\n* Create a notebook inside your home folder in Databricks\n* Create, or attach to, a Spark cluster\n* Import the course files into your home folder\n\n## Audience\n* Primary Audience: Data Engineers\n* Additional Audiences: Data Scientists and Data Pipeline Engineers\n\n## Prerequisites\n\n* Web browser: Please use a <a href=\"https://docs.azuredatabricks.net/user-guide/supported-browsers.html#supported-browsers\" target=\"_blank\">supported browser</a>."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/k0gfd7xdtf?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/k0gfd7xdtf?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### ETL with Databricks and Spark\n\nThe **extract, transform, load (ETL)** process takes data from one or more sources, transforms it, normally by adding structure, and then loads it into a target database. \n\nA common ETL job takes log files from a web server, parses out pertinent fields so it can be readily queried, and then loads it into a database.\n\nETL may seem simple: applying structure to data so itâ€™s in a desired form. However, the complexity of ETL is in the details. Data Engineers building ETL pipelines must understand and apply the following concepts:<br><br>\n\n* Optimizing data formats and connections\n* Determining the ideal schema\n* Handling corrupt records\n* Automating workloads\n\nThis course addresses these concepts.\n\n<img src=\"https://files.training.databricks.com/images/eLearning/ETL-Part-1/ETL-overview.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/>\n\nStay tuned for upcoming courses which will cover:<br><br>\n\n* Complex and performant data transformations\n* Schema changes over time  \n* Recovery from job failures\n* Avoiding duplicate records"],"metadata":{}},{"cell_type":"markdown","source":["## Exercise 1\n\nCreate a notebook and Spark cluster."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/46ztztgeuq?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/46ztztgeuq?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 1\nDatabricks notebooks are backed by clusters, or networked computers, that process data. Create a Spark cluster (*if you already have a running cluster, skip to **Step 3** *):\n1. Select the **Clusters** icon in the sidebar.\n<div><img src=\"https://files.training.databricks.com/images/eLearning/create-cluster-4.png\" style=\"height: 200px; margin: 20px\"/></div>\n2. Click the **Create Cluster** button.\n<div><img src=\"https://files.training.databricks.com/images/eLearning/create-cluster-5.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n3. Name your cluster. Use your name or initials to easily differentiate your cluster from your coworkers.\n4. Select the cluster type. We recommend the latest Databricks runtime (**3.3**, **3.4**, etc.) and Scala **2.11**.\n5. Specify your cluster configuration.\n  * For clusters created on a **Community Edition** shard the default values are sufficient for the remaining fields.\n  * For all other shards, please refer to your company's policy on private clusters.</br></br>\n6. Click the **Create Cluster** button.\n<div><img src=\"https://files.training.databricks.com/images/eLearning/create-cluster-2.png\" style=\"height: 300px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Check with your local system administrator to see if there is a recommended default cluster at your company to use for the rest of the class. This could save you  money!"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 2\n\nCreate a new notebook in your home folder:\n1. Select the **Home** icon in the sidebar.\n<div><img src=\"https://files.training.databricks.com/images/eLearning/home.png\" style=\"height: 200px; margin: 20px\"/></div>\n2. Right-click your home folder.\n3. Select **Create**.\n4. Select **Notebook**.\n<div><img src=\"https://files.training.databricks.com/images/eLearning/create-notebook-1.png\" style=\"height: 150px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n5. Name your notebook `My Notebook`.<br/>\n6. Set the language to **Python**.<br/>\n7. Select the cluster to attach this Notebook.  \n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> If a cluster is not currently running, this option will not exist.\n8. Click **Create**.\n<div>\n  <div style=\"float:left\"><img src=\"https://files.training.databricks.com/images/eLearning/create-notebook-2b.png\" style=\"width:400px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n  <div style=\"float:left; margin-left: e3m; margin-right: 3em\">or</div>\n  <div style=\"float:left\"><img src=\"https://files.training.databricks.com/images/eLearning/create-notebook-2.png\" style=\"width:400px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n  <div style=\"clear:both\"></div>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 3\n\nNow  you have a notebook, use it to run code.\n1. In the first cell of your notebook, type `1 + 1`. \n2. Run the cell: Click the **Run** icon and then select **Run Cell**.\n<div><img src=\"https://files.training.databricks.com/images/eLearning/run-notebook-1.png\" style=\"width:600px; margin-bottom:1em; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> **Ctrl-Enter** also runs a cell."],"metadata":{}},{"cell_type":"code","source":["1 + 1"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["-sandbox\n\n### Attach and Run\n\nIf your notebook was not previously attached to a cluster you might receive the following prompt: \n<div><img src=\"https://files.training.databricks.com/images/eLearning/run-notebook-2.png\" style=\"margin-bottom:1em; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/></div>\n\nIf you click **Attach and Run**, first make sure that you are attaching to the correct cluster.\n\nIf it is not the correct cluster, click **Cancel** instead see the next cell, **Attach & Detach**."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Attach & Detach\n\nIf your notebook is detached you can attach it to another cluster:  \n<img src=\"https://files.training.databricks.com/images/eLearning/attach-to-cluster.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; margin: 20px\"/>\n\nIf your notebook is attached to a cluster you can:\n* Detach your notebook from the cluster.\n* Restart the cluster.\n* Attach to another cluster.\n* Open the Spark UI.\n* View the Driver's log files.\n\n<img src=\"https://files.training.databricks.com/images/eLearning/detach-from-cluster.png\" style=\"margin-bottom:1em; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/>"],"metadata":{}},{"cell_type":"markdown","source":["## Summary\n* Click the down arrow on a folder and select the **Create Notebook** option to create notebooks.\n* Click the down arrow on a folder and select the **Import** option to import notebooks.\n* Select the **Attached/Detached** option directly below the notebook title to attach to a spark cluster \n* Create clusters using the Clusters button on the left sidebar."],"metadata":{}},{"cell_type":"markdown","source":["## Review\n\n**Question:** How do you create a Notebook?  \n**Answer:** Sign into Databricks, select the **Home** icon from the sidebar, right-click your home-folder, select **Create**, and then **Notebook**. In the **Create Notebook** dialog, specify the name of your notebook and the default programming language.\n\n**Question:** How do you create a cluster?  \n**Answer:** Select the **Clusters** icon on the sidebar, click the **Create Cluster** button, specify the specific settings for your cluster and then click **Create Cluster**.\n\n**Question:** How do you attach a notebook to a cluster?  \n**Answer:** If you run a command while detached, you may be prompted to connect to a cluster. To connect to a specific cluster, open the cluster menu by clicking the **Attached/Detached** menu item and then selecting your desired cluster."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n## Next Steps\n\nThis course is available in Python and Scala.  Start the next lesson, **ETL Process Overview**.\n1. Click the **Home** icon in the left sidebar.\n2. Select your home folder.\n3. Select the folder **ETL-Part-1**\n4. Open the notebook **02-ETL-Process-Overview** in either the Python or Scala folder\n\n<img src=\"https://files.training.databricks.com/images/eLearning/ETL-Part-1/Course-Import2-Azure.png\" style=\"margin-bottom: 5px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; width: auto; height: auto; max-height: 383px\"/>\n\n\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> The Python and Scala content is identical except for the language used."],"metadata":{}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n**Q:** Are there additional docs I can reference to find my way around Databricks?  \n**A:** See <a href=\"https://docs.databricks.com/user-guide/getting-started.html\" target=\"_blank\">Getting Started with Databricks</a>.\n\n**Q:** Where can I learn more about the cluster configuration options?  \n**A:** See <a href=\"https://docs.databricks.com/user-guide/clusters/index.html\" target=\"_blank\">Spark Clusters on Databricks</a>.\n\n**Q:** Can I import formats other than .dbc files?  \n**A:** Yes, see <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html#importing-notebooks\" target=\"_blank\">Importing Notebooks</a>.\n\n**Q:** Can I use browsers other than Chrome or Firefox?  \n**A:** Databricks is tested for Chrome and Firefox.  It does work on Internet Explorer 11 and Safari however, it is possible some user-interface features may not work properly.\n\n**Q:** Can I install the courseware notebooks into a non-Databricks distribution of Spark?  \n**A:** No, the files that contain the courseware are in a Databricks specific format (DBC).\n\n**Q:** Do I have to have a paid Databricks subscription to complete this course?  \n**A:** No, you can sign up for a free <a href=\"https://databricks.com/try-databricks\" target=\"_blank\">Community Edition</a> account from Databricks."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2019 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"01-Course-Overview-and-Setup","notebookId":1163192208923042},"nbformat":4,"nbformat_minor":0}
